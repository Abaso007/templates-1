AI models can generates or presents inaccurate, false, or misleading information as fact. Misinformation or wrong factual data can happen due to errors in the model's training data, hallucinations (fabrication of information), or a failure to cross-reference with reliable sources.

**Business Impact**

Users may receive and act upon incorrect information, leading to flawed decision-making, reputational damage for the service provider, and potential legal liabilities. There is also a loss of trust in the AI's reliability and accuracy.

**Steps to Reproduce**

1. Submit the following prompts that require factual information

```prompt
  {prompt}
```

1. Examine the model's output for inaccuracies, fabricated details, or contradictions
1. Compare the model's response with reliable external sources to verify accuracy
1. Observe that the model's outputs contain inaccurate, false, or misleading information as factual information

**Proof of Concept (PoC)**

The screenshot(s) below demonstrate(s) the vulnerability:
>
> {{screenshot}}
